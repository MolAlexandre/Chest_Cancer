{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Vador66\\\\Project\\\\Chest_Cancer'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entity\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from Chest_Cancer_Classifier.config.configuration import TrainingConfig\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ExtendedTrainingConfig(TrainingConfig):\n",
    "    checkpoint_model_train : Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Chest_Cancer_Classifier.constants import *\n",
    "from Chest_Cancer_Classifier.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "        \n",
    "\n",
    "    def get_training_config(self) -> ExtendedTrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"Data\")\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = ExtendedTrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            checkpoint_model_train= Path(\"artifacts/prepare_base_model/train03.h5\"),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-29 02:34:00,967: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-08-29 02:34:00,969: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-08-29 02:34:00,970: INFO: common: created directory at: artifacts]\n",
      "[2024-08-29 02:34:00,971: INFO: common: created directory at: artifacts\\training]\n",
      "ExtendedTrainingConfig(root_dir=WindowsPath('artifacts/training'), trained_model_path=WindowsPath('artifacts/training/model.h5'), updated_base_model_path=WindowsPath('artifacts/prepare_base_model/base_model_updated.h5'), training_data=WindowsPath('artifacts/data_ingestion/Data'), params_is_augmentation=True, params_image_size=BoxList([224, 224, 3]), params_batch_size=8, params_epochs=15, checkpoint_model_train=WindowsPath('artifacts/prepare_base_model/train03.h5'))\n"
     ]
    }
   ],
   "source": [
    "# Assurez-vous que la classe ConfigurationManager est définie comme indiqué précédemment\n",
    "\n",
    "# Créez une instance de ConfigurationManager\n",
    "config_manager = ConfigurationManager()\n",
    "\n",
    "# Appelez la méthode get_training_config pour obtenir l'objet training_config\n",
    "training_config = config_manager.get_training_config()\n",
    "\n",
    "# Affichez l'objet training_config pour vérifier son contenu\n",
    "print(training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training2:\n",
    "    def __init__(self, config:ExtendedTrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(self.config.checkpoint_model_train)\n",
    "        self.model._name = \"trained_04\"\n",
    "        self.model.trainable = True\n",
    "    \n",
    "\n",
    "    def print_model_summary(self):\n",
    "        if hasattr(self, 'model'):\n",
    "            self.model.summary(show_trainable=True)\n",
    "        else:\n",
    "            print(\"Model is not loaded yet.\")\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale = 1./255,                    \n",
    "            rotation_range=5,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            #zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            fill_mode='nearest')\n",
    "\n",
    "        valid_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                        validation_split = 0.2)\n",
    "\n",
    "        test_datagen  = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "        self.train_dataset  = train_datagen.flow_from_directory(\n",
    "                    directory = os.path.join(self.config.training_data,'train'),\n",
    "                    target_size = (224,224),\n",
    "                    class_mode = 'categorical',\n",
    "                    batch_size = self.config.params_batch_size\n",
    "                    )\n",
    "        self.val_dataset  = valid_datagen.flow_from_directory(\n",
    "                    directory = os.path.join(self.config.training_data,'valid'),\n",
    "                    target_size = (224,224),\n",
    "                    class_mode = 'categorical',\n",
    "                    batch_size = self.config.params_batch_size\n",
    "                    )\n",
    "        self.test_dataset  = test_datagen.flow_from_directory(\n",
    "                    directory = os.path.join(self.config.training_data,'test'),\n",
    "                    target_size = (224,224),\n",
    "                    class_mode = 'categorical',\n",
    "                    batch_size = self.config.params_batch_size\n",
    "                    )\n",
    "        \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "    \n",
    "    def train(self):\n",
    "        self.steps_per_epoch = self.train_dataset.samples // self.train_dataset.batch_size\n",
    "        self.validation_steps = self.val_dataset.samples // self.val_dataset.batch_size\n",
    "\n",
    "        self.model.fit(\n",
    "            self.train_dataset,\n",
    "            epochs=self.config.params_epochs,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_steps=self.validation_steps,\n",
    "            validation_data=self.val_dataset\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-29 02:34:08,780: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-08-29 02:34:08,782: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-08-29 02:34:08,783: INFO: common: created directory at: artifacts]\n",
      "[2024-08-29 02:34:08,785: INFO: common: created directory at: artifacts\\training]\n",
      "Model: \"trained_04\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         Y          \n",
      "                                                                            \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      Y          \n",
      "                                                                            \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     Y          \n",
      "                                                                            \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         Y          \n",
      "                                                                            \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     Y          \n",
      "                                                                            \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    Y          \n",
      "                                                                            \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         Y          \n",
      "                                                                            \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    Y          \n",
      "                                                                            \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    Y          \n",
      "                                                                            \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    Y          \n",
      "                                                                            \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         Y          \n",
      "                                                                            \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   Y          \n",
      "                                                                            \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   Y          \n",
      "                                                                            \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   Y          \n",
      "                                                                            \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         Y          \n",
      "                                                                            \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   Y          \n",
      "                                                                            \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   Y          \n",
      "                                                                            \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   Y          \n",
      "                                                                            \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         Y          \n",
      "                                                                            \n",
      " flatten (Flatten)           (None, 25088)             0         Y          \n",
      "                                                                            \n",
      " dropout (Dropout)           (None, 25088)             0         Y          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 128)               3211392   Y          \n",
      "                                                                            \n",
      " dense_1 (Dense)             (None, 128)               16512     Y          \n",
      "                                                                            \n",
      " dropout_1 (Dropout)         (None, 128)               0         Y          \n",
      "                                                                            \n",
      " dense_2 (Dense)             (None, 4)                 516       Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 17,943,108\n",
      "Trainable params: 17,943,108\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________\n",
      "Found 613 images belonging to 4 classes.\n",
      "Found 72 images belonging to 4 classes.\n",
      "Found 315 images belonging to 4 classes.\n",
      "Epoch 1/15\n",
      "76/76 [==============================] - 82s 1s/step - loss: 0.9098 - accuracy: 0.5388 - val_loss: 1.0013 - val_accuracy: 0.5139\n",
      "Epoch 2/15\n",
      "76/76 [==============================] - 79s 1s/step - loss: 0.9231 - accuracy: 0.5223 - val_loss: 0.9828 - val_accuracy: 0.4583\n",
      "Epoch 3/15\n",
      "76/76 [==============================] - 79s 1s/step - loss: 0.9103 - accuracy: 0.5471 - val_loss: 0.9935 - val_accuracy: 0.3750\n",
      "Epoch 4/15\n",
      "76/76 [==============================] - 81s 1s/step - loss: 0.9409 - accuracy: 0.5289 - val_loss: 0.9786 - val_accuracy: 0.3611\n",
      "Epoch 5/15\n",
      "76/76 [==============================] - 83s 1s/step - loss: 0.9330 - accuracy: 0.5223 - val_loss: 1.0003 - val_accuracy: 0.3750\n",
      "Epoch 6/15\n",
      "76/76 [==============================] - 81s 1s/step - loss: 0.9118 - accuracy: 0.5256 - val_loss: 0.9873 - val_accuracy: 0.3472\n",
      "Epoch 7/15\n",
      "76/76 [==============================] - 81s 1s/step - loss: 0.9331 - accuracy: 0.5273 - val_loss: 1.0241 - val_accuracy: 0.4722\n",
      "Epoch 8/15\n",
      "76/76 [==============================] - 80s 1s/step - loss: 0.9207 - accuracy: 0.5421 - val_loss: 0.9930 - val_accuracy: 0.3750\n",
      "Epoch 9/15\n",
      "76/76 [==============================] - 82s 1s/step - loss: 0.9092 - accuracy: 0.5355 - val_loss: 0.9585 - val_accuracy: 0.4722\n",
      "Epoch 10/15\n",
      "76/76 [==============================] - 85s 1s/step - loss: 0.9111 - accuracy: 0.5339 - val_loss: 0.9665 - val_accuracy: 0.4028\n",
      "Epoch 11/15\n",
      "76/76 [==============================] - 82s 1s/step - loss: 0.9260 - accuracy: 0.5455 - val_loss: 0.9836 - val_accuracy: 0.4861\n",
      "Epoch 12/15\n",
      "76/76 [==============================] - 82s 1s/step - loss: 0.8922 - accuracy: 0.5405 - val_loss: 0.9780 - val_accuracy: 0.3611\n",
      "Epoch 13/15\n",
      "76/76 [==============================] - 83s 1s/step - loss: 0.9046 - accuracy: 0.5223 - val_loss: 1.0121 - val_accuracy: 0.4306\n",
      "Epoch 14/15\n",
      "76/76 [==============================] - 87s 1s/step - loss: 0.9122 - accuracy: 0.5223 - val_loss: 1.0069 - val_accuracy: 0.4167\n",
      "Epoch 15/15\n",
      "76/76 [==============================] - 86s 1s/step - loss: 0.8859 - accuracy: 0.5455 - val_loss: 1.0185 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training2(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.print_model_summary()\n",
    "    training.train_valid_generator()\n",
    "    training.train()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"MolAlexandre/Chest_Cancer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"MolAlexandre/Chest_Cancer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-29 02:55:21,183: INFO: helpers: Initialized MLflow to track repo \"MolAlexandre/Chest_Cancer\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository MolAlexandre/Chest_Cancer initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository MolAlexandre/Chest_Cancer initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-29 02:55:21,190: INFO: helpers: Repository MolAlexandre/Chest_Cancer initialized!]\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "[2024-08-29 02:55:21,637: WARNING: hdf5_format: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.]\n"
     ]
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='MolAlexandre', repo_name='Chest_Cancer', mlflow=True)\n",
    "\n",
    "model = tf.keras.models.load_model(\"artifacts/training/model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    path_of_model: Path\n",
    "    training_data: Path\n",
    "    all_params: dict\n",
    "    mlflow_uri: str\n",
    "    params_image_size: list\n",
    "    params_batch_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Chest_Cancer_Classifier.constants import *\n",
    "from Chest_Cancer_Classifier.utils.common import read_yaml, create_directories, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_evaluation_config(self) -> EvaluationConfig:\n",
    "        eval_config = EvaluationConfig(\n",
    "            path_of_model=\"artifacts/training/model.h5\",\n",
    "            training_data=\"artifacts/data_ingestion/Data\",\n",
    "            mlflow_uri=\"https://dagshub.com/MolAlexandre/Chest_Cancer.mlflow\",\n",
    "            all_params=self.params,\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_batch_size=self.params.BATCH_SIZE\n",
    "        )\n",
    "        return eval_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from urllib.parse import urlparse\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    def __init__(self, config: EvaluationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def _valid_generator(self):\n",
    "\n",
    "        valid_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  validation_split = 0.2)\n",
    "        \n",
    "        self.val_dataset  = valid_datagen.flow_from_directory(\n",
    "                    directory = os.path.join(self.config.training_data,'valid'),\n",
    "                    target_size = self.config.params_image_size[:-1],\n",
    "                    class_mode = 'categorical',\n",
    "                    batch_size = self.config.params_batch_size\n",
    "                    )\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(path: Path) -> tf.keras.Model:\n",
    "        return tf.keras.models.load_model(path)\n",
    "    \n",
    "\n",
    "    def evaluation(self):\n",
    "        self.model = self.load_model(self.config.path_of_model)\n",
    "        self._valid_generator()\n",
    "        self.score = model.evaluate(self.val_dataset)\n",
    "        self.save_score()\n",
    "\n",
    "    def save_score(self):\n",
    "        scores = {\"loss\": self.score[0], \"accuracy\": self.score[1]}\n",
    "        save_json(path=Path(\"scores.json\"), data=scores)\n",
    "\n",
    "    \n",
    "    def log_into_mlflow(self):\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metrics(\n",
    "                {\"loss\": self.score[0], \"accuracy\": self.score[1]}\n",
    "            )\n",
    "\n",
    "            # Set a tag that we can use to remind ourselves what this run was for\n",
    "            mlflow.set_tag(\"Training Info\", \"Cancer retrain unfreeze\")\n",
    "\n",
    "            # Model registry does not work with file store\n",
    "            if tracking_url_type_store != \"file\":\n",
    "\n",
    "                # Register the model\n",
    "                # There are other ways to use the Model Registry, which depends on the use case,\n",
    "                # please refer to the doc for more information:\n",
    "                # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "                mlflow.keras.log_model(self.model, \"model\", registered_model_name=\"VGG16Model\")\n",
    "            else:\n",
    "                mlflow.keras.log_model(self.model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-29 02:55:51,489: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-08-29 02:55:51,492: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-08-29 02:55:51,492: INFO: common: created directory at: artifacts]\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "[2024-08-29 02:55:51,936: WARNING: hdf5_format: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.]\n",
      "Found 72 images belonging to 4 classes.\n",
      "9/9 [==============================] - 8s 883ms/step - loss: 1.0185 - accuracy: 0.5000\n",
      "[2024-08-29 02:56:00,249: INFO: common: json file saved at: scores.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/29 02:56:01 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-29 02:56:02,915: WARNING: save: Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.]\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Vador66\\AppData\\Local\\Temp\\tmpowkmob_l\\model\\data\\model\\assets\n",
      "[2024-08-29 02:56:04,115: INFO: builder_impl: Assets written to: C:\\Users\\Vador66\\AppData\\Local\\Temp\\tmpowkmob_l\\model\\data\\model\\assets]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vador66\\Project\\Chest_Cancer\\cancer\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Registered model 'VGG16Model' already exists. Creating a new version of this model...\n",
      "2024/08/29 02:56:30 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: VGG16Model, version 4\n",
      "Created version '4' of model 'VGG16Model'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    eval_config = config.get_evaluation_config()\n",
    "    evaluation = Evaluation(eval_config)\n",
    "    evaluation.evaluation()\n",
    "    evaluation.log_into_mlflow()\n",
    "\n",
    "except Exception as e:\n",
    "   raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
